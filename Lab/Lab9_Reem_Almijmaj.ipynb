{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 9\n",
    "---\n",
    "Hello All,\n",
    "\n",
    "Welcome to the DSCI 510's lab.\n",
    "\n",
    "Guidelines for the Lab:\n",
    "- You will be given the lab assignment in the start of the lab. You're supposed to complete it by the deadline. \n",
    "\n",
    "- You've to complete the assignments individually. If you are having trouble completing the assignment do let me know, I will clear your doubts and guide you but I'll not write code for you and no one else should :) !!!  \n",
    "\n",
    "- You have to fill in the code in this notebook and upload it to back to blackboard for submission. While doing this, make sure that all supporting files that you download from blackboard are in the same directory as this notebook.  \n",
    "\n",
    "- You are encouraged to look up resources online like python docs and stackoverflow. But, you are encouraged to look up the topics and not the questions themselves  \n",
    "\n",
    "- Your last submission will be counted towards your grade  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's lab is about BeautifulSoup and requests.  \n",
    "\n",
    "Some hints before you go: \n",
    "- Use the ```type``` function and ```dir``` function whenever possible to understand what you have vs what did you expect and what you can do with what you have.\n",
    "- Give attention to the brackets while looking at a json so that you know what you will get after parsing it. \n",
    "- Similarly, give attention to the tags while looking at html code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q1.[15 points] \n",
    "---\n",
    "\n",
    "For this question, we will scrape the website \"https://www.dailynews.com/\".  \n",
    "\n",
    "For all news headlines for the website, you have to look for the link to the article and the headline text which **contains the keyword(specifically, in the headline) passed to you in the function argument**.  \n",
    "\n",
    "For the return values, you have to return a list of tuples where a particular tuple's 0th value is the link to the article and the 1st value is the headline text.   \n",
    "\n",
    "Note 1: Keyword and headlines should not be considered case-sensitive.\n",
    "Note 2: Call ```strip()``` over the link and the headline text, so that it is more readable.  \n",
    "\n",
    "FAQs:  \n",
    "Q. How to read/parse a website?  \n",
    "A. For that, as taught in the class you would need to use libraries like BeautifulSoup, urllib or requests.  \n",
    "\n",
    "Q. What am I getting anyway when I read the website?  \n",
    "A. You are getting the whole html code written for the website, when you read/parse the website.  \n",
    "\n",
    "Q. I don't know html, what should I do?  \n",
    "A. No worries. For this lab, you only need to understand that html is another type of a language made up of tags. For example, it has heading info in the *head* tag, paragraph has *p* tag, and html links have *a* tag. So, using the tag, you can get the info you need!  \n",
    "\n",
    "Q. How do I get the tag info?  \n",
    "A. When you get your BeautifulSoup object you can do something like object.find_all('tag') or object('tag') to get all 'tag' tags.  \n",
    "\n",
    "Q. What are tag attributes and how can I access that?  \n",
    "A. HTML attributes are special words used inside the tag to control the element's behaviour. One can access attributes using *get* function.\n",
    "\n",
    "Q. I got the tag, but what I got seems cryptic. What now?  \n",
    "A. So, once you get the info from a particular tag, you get the whole html code inside that tag. If you want some particular information from that, you would need to call functions like get and get_text to get the information directly without messing with the html code.  \n",
    "\n",
    "Q. I am not sure how to use these functions. Help?  \n",
    "A. You can read from the official documentation. Link: https://www.crummy.com/software/BeautifulSoup/bs4/doc/  \n",
    "\n",
    "Good Feature: Use the .prettify() feature of BeautifulSoup. You'll get a better insight of what is that you are scrapping. \n",
    "\n",
    "---\n",
    "\n",
    "Grading Rubric: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_news_of(keyword):\n",
    "    access = requests.get('https://www.dailynews.com/')  #requesting the webpage\n",
    "    content = access.content #taking only the source code\n",
    "    s = BeautifulSoup(content, 'html')  # parse the source code\n",
    "    all_links = s.find_all('a', {\"class\": \"article-title\" }) #take only links that have a link and a title\n",
    "    result = []\n",
    "    lower_keyword = keyword.lower()\n",
    "    for link in all_links:\n",
    "        lower_title= link.attrs['title'].lower()\n",
    "        if lower_keyword in lower_title:\n",
    "            full_link = link.attrs['href'].strip()\n",
    "            full_title = link.attrs['title'].strip()\n",
    "            result.append((full_link,full_title)) #appending list of tuples\n",
    "    return result\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.dailynews.com/2021/10/21/south-la-school-thought-to-be-first-in-county-to-reclose-campus-because-of-coronavirus/',\n",
       "  'South LA school thought to be first in county to reclose campus because of coronavirus'),\n",
       " ('https://www.dailynews.com/2021/10/20/about-1500-lausd-employees-granted-accommodations-for-coronavirus-vaccine-exemptions/',\n",
       "  'About 1,500 LAUSD employees granted accommodations for coronavirus vaccine exemptions'),\n",
       " ('https://www.dailynews.com/2021/10/20/coronavirus-l-a-county-reported-1267-new-cases-and-31-more-deaths-oct-20/',\n",
       "  'Coronavirus: L.A. County reported 1,267 new cases and 31 more deaths, Oct. 20')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_of('Snyder')\n",
    "get_news_of('Coronavirus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.[15 points] \n",
    "---\n",
    "For this question, we will be using requests library to request\n",
    "```api.weather.gov``` to get an airport's weather information. Depending on that, you have to classify whether it is safe to fly or not.  \n",
    "\n",
    "*How to decide if it is safe to fly or not?*  \n",
    "We rely on a simple heuristic for now that if the ```shortForecast``` field has the word cloudy(independent of the case ofcourse) for any of the next three hours, then it is not safe to fly.  \n",
    "\n",
    "Input: String(Airport name)  \n",
    "Output: Boolean(True if safe, False otherwise)  \n",
    "\n",
    "\n",
    "FAQs:  \n",
    "Q. What link should I use for the requests.get() function?  \n",
    "A. Link would look something like this -> https://api.weather.gov/points/ ```<Latitude value>,<Longitude value>```   \n",
    "An Example would be: https://api.weather.gov/points/39.7456,-97.0892\n",
    "\n",
    "Q. I got something after requesting, but, I am not sure, what it is.  \n",
    "A. You recieved a response object. You can call .json() to it and see what is there. (See ```json.dumps()```)  \n",
    "\n",
    "Q. How do I get information from this json?  \n",
    "A. For getting info from that, as taught in the class, you can simply index them by using keys that you want after assessing the json.  \n",
    "\n",
    "Q. Okay, I indexed the json using the keys and I get some list out of it. What is that?  \n",
    "A. That list is the forecast for the next hours. You'll need this information for making the decision that is required in the question. Also, what you are getting in the list is a dict. **Make sure you understand what you are dealing with at each point.**  \n",
    "\n",
    "---\n",
    "\n",
    "Grading Rubric: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_info():\n",
    "    file = open('Airports.txt', encoding='utf8')\n",
    "    values = dict()\n",
    "    cnt = 0\n",
    "    for line in file:\n",
    "        airport_name, coordinates = line.split('\\t')[1], line.split('\\t')[3].split(',')\n",
    "        long, lat = float(coordinates[0][1:]), float(coordinates[1][1:-2])\n",
    "        values[airport_name] = (lat, long)\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "def to_fly_or_not(airport_name):\n",
    "\n",
    "\n",
    "    airport_dict = get_airport_info()\n",
    "    \n",
    "    first_request = requests.get('https://api.weather.gov/points/'+str(airport_dict[airport_name][0]) + \",\" + str(airport_dict[airport_name][1]))\n",
    "    first_r = first_request.json() #Standardized format commonly used to transfer data. Readable by human and machine. \n",
    "\n",
    "    second_request = requests.get(first_r[\"properties\"][\"forecastHourly\"]) #recive the forecashourly link\n",
    "    second_r = second_request.json() #Standardized format commonly used to transfer data. Readable by human and machine. \n",
    "\n",
    "    \n",
    "    for i in second_r['properties']['periods'][0:3]: #only 3 hours that are counts \n",
    "        if 'Cloudy'.lower() in  i[\"shortForecast\"].lower():\n",
    "            return False\n",
    "    else:\n",
    "        return True \n",
    "    \n",
    "    \n",
    "    \n",
    "to_fly_or_not('Los Angeles County Sheriff\\'s Department Heliport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Question.[5 points]\n",
    "---\n",
    "For Question 1, if you want to get headlines daily, there is a possibility that you will be getting the articles that you have already read.  You need to know that which article is new and which article is old. So, how would you solve this problem?\n",
    "\n",
    "You just have to type your solution and not code for it.(I mean you can if you want but you won't get any points for it :))\n",
    "\n",
    "DO NOT ask me about the question. I might give away the solution by mistake! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True = show the new article \n",
    "# False = do not show the article \n",
    "# Loop through the second tuple of the old list (result) to check if the article exists or not. \n",
    "# If it exists return False. Otherwise return True and add that article to the old list. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
